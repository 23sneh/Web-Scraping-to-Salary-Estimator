{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_Data_For_EDA&Models.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[['avg_salary','Rating','Size','Type of ownership','Industry','Sector','Revenue','num_comp','hourly','employer_provided',\n",
    "             'job_state','Same_Location_as_HQ','age','python_jd','spark_jd','aws_jd','excel_jd','job_simp','seniority','desc_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dum = pd.get_dummies(df_model)\n",
    "df_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_dum.drop('avg_salary',axis=1)\n",
    "y = df_dum.avg_salary.values # better pratice to take the .values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_sm = X = sm.add_constant(X)\n",
    "model = sm.OLS(y,X_sm)\n",
    "model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "Neg_MAE = np.mean(cross_val_score(lm,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "print('The negative mean error by using a Linear Regression using its default parameters is: {}'.format(Neg_MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# selecting the best alpha value for Lasso\n",
    "alpha = []\n",
    "error = []\n",
    "for i in range(1,100):\n",
    "    alpha.append(i/100)\n",
    "    lml = Lasso(alpha=(i/100))\n",
    "    error.append(np.mean(cross_val_score(lml,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3)))\n",
    "    \n",
    "plt.plot(alpha,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = tuple(zip(alpha,error))\n",
    "df_err = pd.DataFrame(err, columns = ['alpha','error'])\n",
    "df_err[df_err.error == max(df_err.error)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_l = Lasso(alpha=0.13)\n",
    "lm_l.fit(X_train,y_train)\n",
    "Neg_MAE_Lasso = np.mean(cross_val_score(lm_l,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "print('The negative mean error by using a Lasso Regression using its best alpha value is: {}'.format(Neg_MAE_Lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# fit model no training data\n",
    "Xgb = XGBClassifier()\n",
    "Neg_MAE_Xgboost = np.mean(cross_val_score(Xgb,X_train,y_train, scoring = 'neg_mean_absolute_error', cv= 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The negative mean error by using an XGboost model using its default parameters is: {}'.format(Neg_MAE_Xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "Neg_MAE_RF = np.mean(cross_val_score(rf,X_train,y_train,scoring = 'neg_mean_absolute_error', cv= 3))\n",
    "print('The negative mean error by using a Random Forest model using its default parameters is: {}'.format(Neg_MAE_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train, y_train)\n",
    "lm_l.fit(X_train,y_train)\n",
    "Xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators':range(10,300,10), 'criterion':('mse','mae'), 'max_features':('auto','sqrt','log2')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(rf,parameters,scoring='neg_mean_absolute_error',cv=3)\n",
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
    "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "                      max_samples=None, min_impurity_decrease=0.0,\n",
    "                      min_impurity_split=None, min_samples_leaf=1,\n",
    "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                      n_estimators=270, n_jobs=None, oob_score=False,\n",
    "                      random_state=None, verbose=0, warm_start=False)\n",
    "rf_tuned.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpred_lm = lm.predict(X_test)\n",
    "tpred_lml = lm_l.predict(X_test)\n",
    "tpred_xgboost = Xgb.predict(X_test)\n",
    "tpred_rf = rf_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test,tpred_lm)\n",
    "mean_absolute_error(y_test,tpred_lml)\n",
    "mean_absolute_error(y_test,tpred_xgboost)\n",
    "mean_absolute_error(y_test,tpred_rf)\n",
    "print('The Mean absolute error in Linear Regression Model is: {}'.format(mean_absolute_error(y_test,tpred_lm)))\n",
    "print('The Mean absolute error in Lasso Regression Model is: {}'.format(mean_absolute_error(y_test,tpred_lml)))\n",
    "print('The Mean absolute error in Xgboost Model is: {}'.format(mean_absolute_error(y_test,tpred_xgboost)))\n",
    "print('The Mean absolute error in Random Forest Model is: {}'.format(mean_absolute_error(y_test,tpred_rf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test,(tpred_xgboost+tpred_rf)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving the best model.\n",
    "import pickle\n",
    "pickl = {'model': rf_tuned}\n",
    "pickle.dump( pickl, open( 'model_file' + \".p\", \"wb\" ) )\n",
    "\n",
    "file_name = \"model_file.p\"\n",
    "with open(file_name, 'rb') as pickled:\n",
    "    data = pickle.load(pickled)\n",
    "    model = data['model']\n",
    "\n",
    "print('The predicted salary is: {}'.format(model.predict(np.array(list(X_test.iloc[1,:])).reshape(1,-1))[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
