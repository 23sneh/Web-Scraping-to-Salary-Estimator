{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading my cleaned data from step 2.\n",
    "df = pd.read_csv('cleaned_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## job title and senority\n",
    "## picking up some important job titles related to data science from my data.\n",
    "\n",
    "def title_simplifier(title):\n",
    "    if 'data scientist' in title.lower():\n",
    "        return 'data scientist'\n",
    "    if 'data engineer' in title.lower():\n",
    "        return 'data engineer'\n",
    "    if 'analyst' in title.lower():\n",
    "        return 'analyst'\n",
    "    if 'machine learning' in title.lower():\n",
    "        return 'mle'\n",
    "    if 'manager' in title.lower():\n",
    "        return 'manager'\n",
    "    if 'director' in title.lower():\n",
    "        return 'director'\n",
    "    else:\n",
    "        return 'na'\n",
    "\n",
    "# Which jobs requires senior level exp.\n",
    "def seniority(title):\n",
    "    if 'sr' in title.lower() or 'senior' in title.lower() or 'sr' in title.lower() or 'lead' in title.lower() or 'principal' in title.lower():\n",
    "        return 'senior'\n",
    "    elif 'jr' in title.lower() or 'jr.' in title.lower():\n",
    "        return 'jr'\n",
    "    else:\n",
    "        return 'na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a new column in df.\n",
    "df['job_simp'] = df['Job Title'].apply(title_simplifier)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.job_simp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seniority'] = df['Job Title'].apply(seniority)\n",
    "df.seniority.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_len'] = df['Job Description'].apply(lambda x: len(x))\n",
    "df['desc_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the number of competitors for each company\n",
    "\n",
    "df['num_comp'] = df.Competitors.apply(lambda x: len(x.split(',')) if x != '-1' else 0)\n",
    "df.num_comp.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.hourly==1][['hourly','min_salary','max_salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly wage to annual \n",
    "\n",
    "df['min_salary'] = df.apply(lambda x: x.min_salary*2 if x.hourly == 1 else x.min_salary,axis=1)\n",
    "df['max_salary'] = df.apply(lambda x: x.max_salary*2 if x.hourly == 1 else x.max_salary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.hourly==1][['hourly','min_salary','max_salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove new line from job title\n",
    "\n",
    "df['company_txt'] = df.company_txt.apply(lambda x: x.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.company_txt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting the histogram of each feature. This step gives a lot of information about the data features.\n",
    "df.hist(bins=30, figsize=(20,20),color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oldest company\n",
    "df[df['age']==276]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## company proving lowest salary\n",
    "df[df['min_salary']==15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the most important plot as it shows average salary for each data related fields.\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.boxplot(x='avg_salary',y='job_simp',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,12))\n",
    "sns.boxplot(x='avg_salary',y='job_state',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation plot.\n",
    "correlations = df.corr()\n",
    "f,ax = plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(correlations, annot=True, cmap=\"YlGnBu\", linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = df.select_dtypes(exclude=['int', 'float']).columns #cat Variable\n",
    "\n",
    "numeric_var = df.select_dtypes(include=['int', 'float']).columns # numeric Varible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(df[['age','avg_salary','Rating','desc_len','num_comp']].corr(),vmax=.3, center=0, cmap=cmap,annot=True,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking up some important categorical features for analyses.\n",
    "df_cat = df[['Location', 'Headquarters', 'Size','Type of ownership', 'Industry', 'Sector', 'Revenue', 'company_txt', 'job_state','Same_Location_as_HQ', 'python_jd', 'R_jd',\n",
    "       'spark_jd', 'aws_jd', 'excel_jd', 'job_simp', 'seniority']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting bar graphs for all the important features.\n",
    "for i in df_cat.columns:\n",
    "    cat_num = df_cat[i].value_counts()\n",
    "    print(\"graph for %s: total = %d\" % (i, len(cat_num)))\n",
    "    chart = sns.barplot(x=cat_num.index, y=cat_num)\n",
    "    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some graphs above are not clear. Hence I pick up only the top 20 for such features.\n",
    "for i in df_cat[['Location','Headquarters','company_txt','Industry']].columns:\n",
    "    cat_num = df_cat[i].value_counts()[:20]\n",
    "    print(\"graph for %s: total = %d\" % (i, len(cat_num)))\n",
    "    chart = sns.barplot(x=cat_num.index, y=cat_num)\n",
    "    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg salary as per job positions.\n",
    "pd.pivot_table(df,index='job_simp', values='avg_salary').sort_values('avg_salary', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg salary in each state.\n",
    "pd.pivot_table(df,index='job_state',values='avg_salary').sort_values('avg_salary', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg salary as per different sectors.\n",
    "pd.pivot_table(df,index='Sector',values='avg_salary').sort_values('avg_salary', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avg salary as per company renevue\n",
    "pd.pivot_table(df,index='Revenue',values='avg_salary').sort_values('avg_salary', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg salary for a data scientist as per states.\n",
    "pd.pivot_table(df[df.job_simp == 'data scientist'], index = 'job_state', values = 'avg_salary').sort_values('avg_salary', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivots = df[['Rating', 'Industry', 'Sector', 'Revenue', 'num_comp', 'hourly', 'employer_provided', 'python_jd', 'R_jd', 'spark_jd', 'aws_jd', 'excel_jd', 'Type of ownership','avg_salary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot tables for some important features with respect to avg_salary.\n",
    "for i in df_pivots.columns:\n",
    "    print(i)\n",
    "    print(pd.pivot_table(df_pivots, index = i, values= 'avg_salary').sort_values('avg_salary',ascending= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = \" \".join(df['Job Description'])\n",
    "\n",
    "def punctuation_stop(text):\n",
    "    \"\"\"remove punctuation and stop words\"\"\"\n",
    "    filtered = []\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and w.isalpha():\n",
    "            filtered.append(w.lower())\n",
    "    return filtered\n",
    "\n",
    "\n",
    "words_filtered = punctuation_stop(words)\n",
    "\n",
    "text = \" \".join([ele for ele in words_filtered])\n",
    "\n",
    "wc= WordCloud(background_color=\"white\", random_state=1,stopwords=STOPWORDS, max_words = 2000, width =800, height = 1500)\n",
    "wc.generate(text)\n",
    "\n",
    "plt.figure(figsize=[15,30])\n",
    "plt.imshow(wc,interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
